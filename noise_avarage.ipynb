{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting hourly avarage for noise\n",
    "\n",
    "noise= pd.read_csv('noise_data/noise_data_complete.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8593 entries, 0 to 8592\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   result_timestamp  8593 non-null   object \n",
      " 1   noise_level       8593 non-null   float64\n",
      " 2   comp              8593 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 201.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_level</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>55.88125</td>\n",
       "      <td>Intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>58.05625</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>51.57500</td>\n",
       "      <td>Intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>48.67500</td>\n",
       "      <td>Intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>46.12500</td>\n",
       "      <td>Intermediate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      result_timestamp  noise_level          comp\n",
       "0  2022-01-01 00:00:00     55.88125  Intermediate\n",
       "1  2022-01-01 01:00:00     58.05625          High\n",
       "2  2022-01-01 02:00:00     51.57500  Intermediate\n",
       "3  2022-01-01 03:00:00     48.67500  Intermediate\n",
       "4  2022-01-01 04:00:00     46.12500  Intermediate"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.info()\n",
    "noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise['result_timestamp'] = pd.to_datetime(noise['result_timestamp'])\n",
    "\n",
    "# Extract the day of the week (0 = Monday, 6 = Sunday)\n",
    "noise['DayOfWeek'] = noise['result_timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_timestamp</th>\n",
       "      <th>noise_level</th>\n",
       "      <th>comp</th>\n",
       "      <th>DayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>55.88125</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>58.05625</td>\n",
       "      <td>High</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>51.57500</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>48.67500</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>46.12500</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     result_timestamp  noise_level          comp  DayOfWeek\n",
       "0 2022-01-01 00:00:00     55.88125  Intermediate          5\n",
       "1 2022-01-01 01:00:00     58.05625          High          5\n",
       "2 2022-01-01 02:00:00     51.57500  Intermediate          5\n",
       "3 2022-01-01 03:00:00     48.67500  Intermediate          5\n",
       "4 2022-01-01 04:00:00     46.12500  Intermediate          5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     DayOfWeek  HourOfDay  AverageNoise\n",
      "0            0          0     48.654779\n",
      "1            0          1     45.111201\n",
      "2            0          2     42.809967\n",
      "3            0          3     41.655523\n",
      "4            0          4     41.753627\n",
      "..         ...        ...           ...\n",
      "163          6         19     58.750359\n",
      "164          6         20     58.612157\n",
      "165          6         21     57.614714\n",
      "166          6         22     55.675384\n",
      "167          6         23     52.711250\n",
      "\n",
      "[168 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by the hour of the week (day of the week and hour of the day)\n",
    "df_hourly_avg = noise.groupby(['DayOfWeek', noise['result_timestamp'].dt.hour])['noise_level'].mean().reset_index()\n",
    "# Rename the columns for clarity\n",
    "df_hourly_avg.columns = ['DayOfWeek', 'HourOfDay', 'AverageNoise']\n",
    "\n",
    "# Preview the resulting dataset\n",
    "print(df_hourly_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_avg.to_csv('hourly_acg_noise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seleniumNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached selenium-4.9.1-py3-none-any.whl (6.6 MB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Using cached trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\joaod\\anaconda3\\envs\\mda\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\joaod\\anaconda3\\envs\\mda\\lib\\site-packages (from selenium) (2.0.2)\n",
      "Collecting trio~=0.17\n",
      "  Using cached trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "Collecting sortedcontainers\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\joaod\\anaconda3\\envs\\mda\\lib\\site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Collecting sniffio\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Using cached exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting cffi>=1.14\n",
      "  Downloading cffi-1.15.1-cp39-cp39-win_amd64.whl (179 kB)\n",
      "     -------------------------------------- 179.1/179.1 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna in c:\\users\\joaod\\anaconda3\\envs\\mda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     ------------------------------------ 118.7/118.7 kB 695.2 kB/s eta 0:00:00\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sortedcontainers, sniffio, pysocks, pycparser, outcome, h11, exceptiongroup, async-generator, wsproto, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed async-generator-1.10 cffi-1.15.1 exceptiongroup-1.1.1 h11-0.14.0 outcome-1.2.0 pycparser-2.21 pysocks-1.7.1 selenium-4.9.1 sniffio-1.3.0 sortedcontainers-2.4.0 trio-0.22.0 trio-websocket-0.10.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "#importing packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '4'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     f\u001b[39m.\u001b[39mwrite(response_class\u001b[39m.\u001b[39mcontent)\n\u001b[0;32m     12\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mclassifier_trained_model.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m---> 13\u001b[0m     rfc \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[0;32m     15\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRegressor_trained_model.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     16\u001b[0m     f\u001b[39m.\u001b[39mwrite(response_reg\u001b[39m.\u001b[39mcontent)\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '4'."
     ]
    }
   ],
   "source": [
    "#importing models\n",
    "\n",
    "url_class = 'https://raw.githubusercontent.com/joaodpcm/MDA/main/classifier_trained_model.pkl'\n",
    "response_class = requests.get(url_class)\n",
    "\n",
    "url_reg= 'https://raw.githubusercontent.com/joaodpcm/MDA/main/Regressor_trained_model.pkl'\n",
    "response_reg= requests.get(url_reg)\n",
    "\n",
    "with open('classifier_trained_model.pkl', 'wb') as f:\n",
    "    f.write(response_class.content)\n",
    "\n",
    "with open('classifier_trained_model.pkl', 'rb') as f:\n",
    "    rfc = pickle.load(f)\n",
    "\n",
    "with open('Regressor_trained_model.pkl','wb') as f:\n",
    "    f.write(response_reg.content)\n",
    "\n",
    "with open('Regressor_trained_model.pkl', 'rb') as f:\n",
    "    hgr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(datetime\u001b[39m.\u001b[39;49mversion)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '4'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mclassifier_trained_model.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     rfc \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[0;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRegressor_trained_model.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     hgr \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '4'."
     ]
    }
   ],
   "source": [
    "with open('classifier_trained_model.pkl', 'rb') as f:\n",
    "    rfc = pickle.load(f)\n",
    "\n",
    "with open('Regressor_trained_model.pkl', 'rb') as f:\n",
    "    hgr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing avarage of the noise\n",
    "df_hourly_avg=pd.read_csv('noise_data/hourly_acg_noise.csv')\n",
    "\n",
    "# Retrieve the current date and time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Create a range of dates and times for the next 48 hours\n",
    "time_range = pd.date_range(start=current_time, periods=48, freq='H')\n",
    "# Filter the dataset for the next 48 hours\n",
    "filtered_data = df_hourly_avg[\n",
    "    (df_hourly_avg['DayOfWeek'] == current_time.weekday()) &\n",
    "    (df_hourly_avg['HourOfDay'].isin(time_range.hour))\n",
    "]\n",
    "\n",
    "events=pd.read_csv('shaped_filter_tags_city2_EXAM.csv')\n",
    "events['Time'] = pd.to_datetime(events['Time'])\n",
    "events_48 = events[events['Time'].isin(time_range)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading unseen data\n",
    "content = \"https://weather.com/weather/hourbyhour/l/c097b546627cdff2da1e276cb9b2731055718a5e7270d777a92857a9701c7870\"\n",
    "response = requests.get(content)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "temp_val = soup.findAll('div', attrs={'class':'DetailsTable--field--CPpc_'})\n",
    "\n",
    "\n",
    "forecast = pd.DataFrame()\n",
    "forecast['temp'] = [round((int(temp_val[i].text[-3:-1])-32 ) *5/9, 1) for i in list(np.array(range(288))) if i%6 == 0]\n",
    "forecast['wind'] = [float(temp_val[i].text.split(' ')[1]) for i in list(np.array(range(288))) if i%6 == 1]\n",
    "forecast['wind_direction'] = [temp_val[i].text.split(' ')[0] for i in list(np.array(range(288))) if i%6 == 1]\n",
    "forecast['humidity'] = [int(temp_val[i].text[-3:-1]) for i in list(np.array(range(288))) if i%6 == 2]\n",
    "forecast['cloud_cover'] = [int(temp_val[i].text.replace('Cloud Cover', '')[:-1]) for i in list(np.array(range(288))) if i%6 == 4]\n",
    "forecast['rain'] = [int(temp_val[i].text.replace('Rain Amount', '').replace(' in', '')) for i in list(np.array(range(288))) if i%6 == 5]\n",
    "weekday = [(datetime.now()+timedelta(hours=i)).weekday() for i in range(48)]\n",
    "hour_of_day = [(datetime.now()+timedelta(hours=i)).hour for i in range(48)]\n",
    "forecast['nameday'] = weekday\n",
    "forecast['hour'] = hour_of_day\n",
    "forecast['event_yes'] = False # This value has to be included by the user. So edit this. The value now is missing, but the model running, so even if nothing is provided, it will run\n",
    "forecast['tag_category'] = 'No event' # This value has to be included by the user. So edit this\n",
    "forecast['# of events'] = events_48['Events']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making prediction on unseen data\n",
    "prediction_reg = hgr.predict(forecast)\n",
    "\n",
    "prediction_class = rfc.predict(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#making a graph for the classifier\n",
    "colors = {\"Low\": \"green\", \"Intermediate\": \"yellow\", \"High\": \"red\"}\n",
    "category_order = [\"Low\", \"Intermediate\", \"High\"]\n",
    "fig_class = go.Figure(data=[go.Bar(x=forecast['hour'],\n",
    "                            y=prediction_class,\n",
    "                            marker=dict(color=[colors[level] for level in prediction_class]),\n",
    "                            customdata=prediction_class,\n",
    "                            hovertemplate=\"Hour: %{x}<br>Noise Level: %{customdata}<extra></extra>\")])\n",
    "fig_class.update_xaxes(title_text=\"Hours\")\n",
    "fig_class.update_yaxes(title_text=\"Noise Level\", categoryorder=\"array\", categoryarray=category_order)\n",
    "fig_class.update_layout(title_text=\"Relative Noise Levels in the Next 48 Hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#making a graph for the regressor\n",
    "fig_reg = go.Figure()\n",
    "fig_reg.add_trace(data=go.Scatter(x=forecast['hour'], y=prediction_reg, name='Noise Forecast'))\n",
    "fig_reg.add_trace(go.Scatter(x=time_range, y=filtered_data['AverageNoise'], mode='lines', name='Average Noise',line=dict(dash='dash')))\n",
    "\n",
    "fig_reg.update_xaxes(title_text=\"Hours\")\n",
    "fig_reg.update_yaxes(title_text=\"dB\")\n",
    "fig_reg.update_layout(title_text=\"Noise Forecast vs Avarage for the next 48 hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#App\n",
    "st.title(\"Noise forecast\")\n",
    "\n",
    "# Create a table with checkboxes for each hour\n",
    "st.header(\"Are there any events on the next two days?\")\n",
    "selected_hours = st.multiselect('Select hours for the event', forecast['hour'], default=[])\n",
    "# Update the 'Event' column based on the selected hours\n",
    "forecast.loc[forecast['hour'].isin(selected_hours), 'Event'] = True\n",
    "#Update tag\n",
    "for hour in selected_hours:\n",
    "    event_type = st.selectbox(f'Select event type for {hour}',['Party', 'Sports', 'Cultural', 'Pub Crawl'])\n",
    "    forecast.loc[forecast['hour']==hour, 'tag_category']=event_type\n",
    "\n",
    "st.header(\"Noise levels for the next 2 days\")\n",
    "st.plotly_chart(fig_class)\n",
    "st.markdown(\"This graph shows a categorical prediction for the noise level for the next 48 hours relative to the usual noise levels on these hours. \"\n",
    "            '<span style=\"color:red\">The red bars indicate hours that will be louder than usual.</span>'  \n",
    "            '<span style=\"color:yellow\">The yellow bars indicate hours that will be like the usual.</span>'\n",
    "             '<span style=\"color:green\">The green bars indicate hours that will be calmer than usual.</span>',unsafe_allow_html=True)\n",
    "st.plotly_chart(fig_reg)\n",
    "st.markdown('This graph shows the absolute levels of noise expected for the next 48 hours in the continuous line, and the avarage of these hours in the dotted line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
