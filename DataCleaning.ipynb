{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Meteo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If local data\n",
    "#put the folder of the dataset in the same folder as the code with the name meteo_data\n",
    "\n",
    "Q1 = pd.read_csv('meteo_data/LC_2022Q1.csv')\n",
    "Q2 = pd.read_csv('meteo_data/LC_2022Q2.csv')\n",
    "Q3 = pd.read_csv('meteo_data/LC_2022Q3.csv')\n",
    "Q4 = pd.read_csv('meteo_data/LC_2022Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#If google drive\n",
    "# Set up a project in the Google API Console and enable the Google Drive API.\n",
    "\n",
    "# Install the PyDrive library using pip: `pip install PyDrive`\n",
    "\n",
    "# Authenticate with your Google account.\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth()  # Follow the instructions to authenticate with your Google account\n",
    "\n",
    "# Step 4: Use the PyDrive client to retrieve the folder or file ID of the data you want to access.\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# specify folders links\n",
    "MeteoLink = \"https://drive.google.com/drive/folders/1KznKVQzrCpRLgXyXsI2Yz0o2xzqO2CZo?usp=share_link\"\n",
    "\n",
    "# getting folders id\n",
    "MeteoId = MeteoLink.split('/')[-1]\n",
    "\n",
    "# getting folder by id\n",
    "meteo = drive.CreateFile({'id': MeteoId})\n",
    "meteo.FetchMetadata()\n",
    "\n",
    "# getting files in the folders\n",
    "MeteoFileList = drive.ListFile({'q': \"'%s' in parents and trashed=false\" % MeteoId}).GetList()\n",
    "print (MeteoFileList[0])'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying missing values of Q1\n",
    "\n",
    "Q1MissingValuesCount = Q1.isnull().sum()\n",
    "Q1MissingValuesRatio = Q1.isnull().mean()\n",
    "print(Q1MissingValuesRatio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns\n",
    "Q1Drop = Q1.drop(['LC_DWPTEMP', 'LC_n','LC_RAD','LC_WINDDIR','LC_RAD60','LC_TEMP_QCL0','LC_TEMP_QCL1','LC_TEMP_QCL2'], axis=1)\n",
    "hum = 'LC_HUMIDITY'\n",
    "temp = 'LC_TEMP_QCL3'\n",
    "rain = 'LC_RAININ'\n",
    "dailyRain = 'LC_DAILYRAIN'\n",
    "wind='LC_WINDSPEED'\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "\n",
    "# create an instance of the StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering by location near the noise spots\n",
    "id=Q1Drop['ID'].unique()\n",
    "print(id)\n",
    "Ids = ['LC-102', 'LC-117', 'LC-112', 'LC-118']\n",
    "Q1DropIDfilter = Q1Drop.loc[Q1Drop['ID'].isin(Ids)]\n",
    "print(Q1DropIDfilter['ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "Q1DropIDfilter[[hum,temp,rain,dailyRain,wind]] = scaler.fit_transform(Q1DropIDfilter[[hum,temp,rain,dailyRain,wind]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN transform\n",
    "Q1DropIDfilter[[hum,temp,rain,dailyRain,wind]] = imputer.fit_transform(Q1DropIDfilter[[hum,temp,rain,dailyRain,wind]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying missing values of Q2\n",
    "\n",
    "Q2MissingValuesCount = Q2.isnull().sum()\n",
    "Q2MissingValuesRatio = Q2.isnull().mean()\n",
    "print(Q2MissingValuesRatio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying missing values in Q3\n",
    "\n",
    "Q3MissingValuesCount = Q3.isnull().sum()\n",
    "Q3MissingValuesRatio = Q3.isnull().mean()\n",
    "print(Q3MissingValuesRatio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying missing values in Q4\n",
    "Q4MissingValuesCount = Q4.isnull().sum()\n",
    "Q4MissingValuesRatio = Q4.isnull().mean()\n",
    "print(Q4MissingValuesRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the four Qs\n",
    "\n",
    "year = pd.concat([Q1,Q2,Q3,Q4], ignore_index=True)\n",
    "yearMissingValuesCount = year.isnull().sum()\n",
    "yearMissingValuesRatio = year.isnull().mean()\n",
    "\n",
    "print(yearMissingValuesRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns\n",
    "yearDrop = year.drop(['LC_DWPTEMP', 'LC_n','LC_RAD','LC_WINDDIR','LC_RAD60','LC_TEMP_QCL0','LC_TEMP_QCL1','LC_TEMP_QCL2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering by location near the noise spots\n",
    "id=yearDrop['ID'].unique()\n",
    "print(id)\n",
    "Ids = ['LC-102', 'LC-117', 'LC-112', 'LC-118']\n",
    "yearDropIDfilter = yearDrop.loc[yearDrop['ID'].isin(Ids)]\n",
    "print(yearDropIDfilter['ID'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimating the missing values with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize the data\n",
    "yearDropIDfilter[[hum,temp,rain,dailyRain,wind]] = scaler.fit_transform(yearDropIDfilter[[hum,temp,rain,dailyRain,wind]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN transform\n",
    "yearDropIDfilter[[hum,temp,rain,dailyRain,wind]] = imputer.fit_transform(yearDropIDfilter[[hum,temp,rain,dailyRain,wind]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert the imputed data back to original scale\n",
    "yearDrop[[hum,temp,rain,dailyRain,wind]] = scaler.inverse_transform(yearDrop[[hum,temp,rain,dailyRain,wind]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset of the year for the 4 stations in namsestrat with humidity, temperature, wind, rain and daily rain\n",
    "\n",
    "print(yearDrop)\n",
    "yearDrop.to_csv('YearProcessed.csv', index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking variance over time among the 4 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'data' containing the weather measurements\n",
    "\n",
    "# Step 1: Calculate the mean temperature, humidity, and wind for each date\n",
    "mean_values = yearDrop.groupby('Date').mean()\n",
    "\n",
    "# Step 2: Calculate the variance of temperature, humidity, and wind for each date\n",
    "variance_values = yearDrop.groupby('Date').var()\n",
    "\n",
    "# Step 3: Plot the variances over time\n",
    "plt.plot(variance_values.index, variance_values[temp], label='Temperature Variance')\n",
    "plt.plot(variance_values.index, variance_values[hum], label='Humidity Variance')\n",
    "plt.plot(variance_values.index, variance_values[wind], label='Wind Variance')\n",
    "plt.plot(variance_values.index, variance_values[rain], label='Rain Variance')\n",
    "plt.plot(variance_values.index, variance_values[dailyRain], label='Daily rain Variance')\n",
    "\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Variance of Weather Measurements')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearMissingValuesRemoved = year.dropna()\n",
    "print(yearMissingValuesRemoved.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(yearMissingValuesRemoved['Date'],yearMissingValuesRemoved['LC_TEMP_QCL0'], s=5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('TEMP_QCL0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(yearMissingValuesRemoved['Date'],yearMissingValuesRemoved['LC_TEMP_QCL1'], s=5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('TEMP_QCL1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(yearMissingValuesRemoved['Date'],yearMissingValuesRemoved['LC_TEMP_QCL2'], s=5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('TEMP_QCL2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(yearMissingValuesRemoved['Date'],yearMissingValuesRemoved['LC_TEMP_QCL3'], s=5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('TEMP_QCL3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering by location near the noise spots\n",
    "id=yearMissingValuesRemoved['ID'].unique()\n",
    "print(id)\n",
    "Ids = ['LC-102', 'LC-117', 'LC-112', 'LC-118']\n",
    "FilteredByLocation = yearMissingValuesRemoved.loc[yearMissingValuesRemoved['ID'].isin(Ids)]\n",
    "print(FilteredByLocation['ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 'LC_TEMP_QCL3'\n",
    "df_grouped = FilteredByLocation.groupby(['ID', 'Date'])[temp].mean().reset_index()\n",
    "\n",
    "# create a pivot table with ID as rows, date as columns, and temperature as values\n",
    "df_pivot = df_grouped.pivot(index='Date', columns='ID', values=temp)\n",
    "\n",
    "# plot the data\n",
    "df_pivot.plot(kind='line')\n",
    "#plt.xlim(['2022-02-01','2022-03-01'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Temperature by ID and Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped1 = yearMissingValuesRemoved.groupby(['ID', 'Date'])[temp].mean().reset_index()\n",
    "\n",
    "# create a pivot table with ID as rows, date as columns, and temperature as values\n",
    "df_pivot1 = df_grouped1.pivot(index='Date', columns='ID', values=temp)\n",
    "\n",
    "# plot the data\n",
    "df_pivot1.plot(kind='line')\n",
    "#plt.xlim(['2022-02-01','2022-03-01'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Temperature by ID and Date')\n",
    "plt.legend('None')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is called df\n",
    "fig = go.Figure()\n",
    "\n",
    "# Create a scatter plot for each ID\n",
    "for id, data in yearMissingValuesRemoved.groupby('ID'):\n",
    "    fig.add_trace(go.Scatter(x=data['Date'], y=data[temp], name=id))\n",
    "\n",
    "# Add x and y axis labels\n",
    "fig.update_xaxes(title='Date')\n",
    "fig.update_yaxes(title='Temperature')\n",
    "fig.update_layout(showlegend=False)\n",
    "# Set the title\n",
    "fig.update_layout(title='Temperature vs. Date for all IDs')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1MissingValuesRemoved = Q1.dropna()\n",
    "Q2MissingValuesRemoved = Q2.dropna()\n",
    "Q3MissingValuesRemoved = Q3.dropna()\n",
    "Q4MissingValuesRemoved = Q4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Q1MissingValuesRemoved['Date'],Q1MissingValuesRemoved['LC_HUMIDITY'],s=5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Humidity')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metadata = pd.read_csv('meteo_data/01_Metadata_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Metadata.columns)\n",
    "print(Metadata['SVF'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
